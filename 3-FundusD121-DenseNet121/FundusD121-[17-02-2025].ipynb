{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "$$ \\huge \\textbf{FundusD121: DenseNet121 Model} $$ üî¨üëÅÔ∏è  \n",
        "</center>\n",
        "\n",
        "**Purpose:**  \n",
        "- üí° Classifies fundus images as 'Normal' or 'AbNormal' for Alzheimer's detection.\n",
        "\n",
        "**Model Overview:**  \n",
        "- üîë **Backbone:** DenseNet121 ‚Äî A dense convolutional network with 121 layers, improving feature reuse.\n",
        "\n",
        "**Techniques Used:**  \n",
        "- üîÑ **Transfer Learning:** Using pre-trained ImageNet weights.  \n",
        "- ‚öñÔ∏è **Binary Cross-Entropy Loss** for binary classification.  \n",
        "- üßë‚Äçüè´ **Adam Optimizer** with a learning rate of **0.0001**.  \n",
        "- ‚öñÔ∏è **Class Weight Balancing** for addressing imbalanced data.  \n",
        "- ‚è±Ô∏è **Callbacks:** Early stopping & ReduceLROnPlateau to speed up training."
      ],
      "metadata": {
        "id": "dQDemN5BfAMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# ‚úÖ **Mount Google Drive**\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ‚úÖ **Dataset Path**\n",
        "dataset_path = \"/content/drive/MyDrive/Fundus-ModelData\"\n",
        "\n",
        "train_dir = os.path.join(dataset_path, \"Test-Imgs\")\n",
        "test_dir = os.path.join(dataset_path, \"Train-Imgs\")\n",
        "\n",
        "# ‚úÖ **Hyperparameters**\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "# ‚úÖ **Data Augmentation**\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# ‚úÖ **Load Data**\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\",\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\",\n",
        "    subset=\"validation\"\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\",\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# ‚úÖ **Handle Class Imbalance (Class Weights)**\n",
        "class_labels = np.array(train_generator.classes)\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(class_labels),\n",
        "    y=class_labels\n",
        ")\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "print(f\"Class Weights: {class_weight_dict}\")\n",
        "\n",
        "# ‚úÖ **Load DenseNet121 (Pretrained)**\n",
        "base_model = DenseNet121(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze base model\n",
        "\n",
        "# ‚úÖ **Add Custom Layers**\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "# ‚úÖ **Compile Model**\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# ‚úÖ **Model Saving Paths**\n",
        "best_model_path = \"/content/drive/MyDrive/draft_models/densenet121_best.h5\"\n",
        "final_model_path = \"/content/drive/MyDrive/draft_models/densenet121_final.h5\"\n",
        "saved_model_dir = \"/content/drive/MyDrive/draft_models/densenet121_saved_model.h5\"\n",
        "\n",
        "# ‚úÖ **Callbacks**\n",
        "checkpoint = ModelCheckpoint(\n",
        "    best_model_path, monitor=\"val_loss\", save_best_only=True, mode=\"min\", verbose=1\n",
        ")\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True)\n",
        "\n",
        "# ‚úÖ **Train the Model**\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=EPOCHS,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[checkpoint, reduce_lr, early_stopping]\n",
        ")\n",
        "\n",
        "# ‚úÖ **Save the Final Model**\n",
        "model.save(final_model_path)\n",
        "model.save(saved_model_dir)  # No need to specify save_format\n",
        "print(f\"Model saved at: {final_model_path} and {saved_model_dir}\")\n",
        "\n",
        "# ‚úÖ **Plot Training Curves**\n",
        "def plot_training_curves(history):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Accuracy Plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "    plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Training & Validation Accuracy\")\n",
        "\n",
        "    # Loss Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
        "    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_training_curves(history)"
      ],
      "metadata": {
        "id": "W7drJwxc2hk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction:**\n",
        "- üßë‚Äçüíª Predict the 'Normal' or 'AbNormal' status of new fundus images.\n",
        "\n",
        "**Steps:**\n",
        "1. üìÇ Load the model that has been trained.  \n",
        "2. üîÑ Preprocess the new images (resize, normalize).  \n",
        "3. üìä Use the model to predict the class of the images.  \n",
        "4. üßê Show the prediction results with confidence scores."
      ],
      "metadata": {
        "id": "nGGzwZoPfFFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from fpdf import FPDF\n",
        "from google.colab import drive\n",
        "\n",
        "# üöÄ Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# üîç Define paths\n",
        "model_path = \"/content/drive/MyDrive/Fundus-ModelData/Saved-Models/4-FundusD121-DenseNet121/FundusD121.h5\"\n",
        "test_folder = \"/content/drive/MyDrive/Fundus-ModelData/Test-Imgs\"\n",
        "output_pdf_path = \"/content/drive/MyDrive/Fundus-ModelData/Saved-Models/4-FundusD121-DenseNet121/FundusD121\"\n",
        "\n",
        "# üß† Load Trained Model\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# üñº Preprocess Image\n",
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, target_size=(224, 224))  # Resize\n",
        "    img_array = img_to_array(img) / 255.0  # Normalize\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    return img_array\n",
        "\n",
        "# üìÇ Process Images & Predict\n",
        "results = []\n",
        "class_counts = {}\n",
        "confidence_scores = {}\n",
        "threshold = 0.5  # Sigmoid activation threshold\n",
        "\n",
        "for subfolder in os.listdir(test_folder):\n",
        "    subfolder_path = os.path.join(test_folder, subfolder)\n",
        "\n",
        "    if os.path.isdir(subfolder_path):  # Ensure it's a folder\n",
        "        class_counts[subfolder] = {\"Normal\": 0, \"Abnormal\": 0}\n",
        "        confidence_scores[subfolder] = []\n",
        "\n",
        "        for image_name in os.listdir(subfolder_path):\n",
        "            image_path = os.path.join(subfolder_path, image_name)\n",
        "\n",
        "            # Predict class\n",
        "            img_array = preprocess_image(image_path)\n",
        "            prediction = model.predict(img_array)[0][0]\n",
        "            predicted_class = \"Abnormal\" if prediction > threshold else \"Normal\"\n",
        "            confidence_score = round(prediction, 4)\n",
        "\n",
        "            # Track counts & confidence\n",
        "            class_counts[subfolder][predicted_class] += 1\n",
        "            confidence_scores[subfolder].append(confidence_score)\n",
        "\n",
        "            # Store results\n",
        "            results.append([image_name, subfolder, predicted_class, confidence_score])\n",
        "\n",
        "# üìù Convert results to DataFrame\n",
        "df = pd.DataFrame(results, columns=[\"Image Name\", \"Folder\", \"Predicted Class\", \"Confidence Score\"])\n",
        "\n",
        "# üé® Generate Data Visualizations\n",
        "fig, axes = plt.subplots(1, len(class_counts), figsize=(10, 5))\n",
        "for i, (folder, counts) in enumerate(class_counts.items()):\n",
        "    labels = counts.keys()\n",
        "    sizes = counts.values()\n",
        "    axes[i].pie(sizes, labels=labels, autopct=\"%1.1f%%\", startangle=90, colors=[\"lightblue\", \"salmon\"])\n",
        "    axes[i].set_title(f\"Class Distribution in {folder}\")\n",
        "plt.savefig(\"/content/class_distribution.png\")\n",
        "\n",
        "# üìä Average Confidence per Folder\n",
        "avg_confidence = {folder: np.mean(scores) for folder, scores in confidence_scores.items()}\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.bar(avg_confidence.keys(), avg_confidence.values(), color=\"skyblue\")\n",
        "plt.xlabel(\"Folders\")\n",
        "plt.ylabel(\"Average Confidence Score\")\n",
        "plt.title(\"Average Confidence Score per Subfolder\")\n",
        "plt.savefig(\"/content/avg_confidence.png\")\n",
        "\n",
        "!pip install fpdf\n",
        "\n",
        "# üìÑ Generate PDF Report\n",
        "class PDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font(\"Times\", \"B\", 16)\n",
        "        self.cell(275, 10, \"Fundus Image Classification Report\", ln=True, align=\"C\")\n",
        "\n",
        "    def footer(self):\n",
        "        self.set_y(-15)\n",
        "        self.set_font(\"Times\", \"I\", 10)\n",
        "        self.cell(0, 10, f\"Page {self.page_no()}\", align=\"C\")\n",
        "\n",
        "# üìë Create PDF\n",
        "pdf = PDF(orientation=\"L\")\n",
        "pdf.set_auto_page_break(auto=True, margin=15)\n",
        "pdf.add_page()\n",
        "pdf.set_font(\"Times\", size=12)\n",
        "\n",
        "# üè∑ Report Header\n",
        "pdf.set_font(\"Times\", \"B\", 14)\n",
        "pdf.cell(0, 10, \"Model Details\", ln=True)\n",
        "pdf.set_font(\"Times\", size=12)\n",
        "pdf.cell(0, 10, f\"Model Name: FundusD121\", ln=True)\n",
        "#pdf.cell(0, 10, f\"Model Path: {model_path}\", ln=True)\n",
        "pdf.cell(0, 10, \"Author: Danish A. G.\", ln=True)\n",
        "pdf.ln(10)\n",
        "\n",
        "# üìã Results Table\n",
        "pdf.set_font(\"Times\", \"B\", 12)\n",
        "pdf.cell(140, 10, \"Image Name\", 1)\n",
        "pdf.cell(40, 10, \"Folder\", 1)\n",
        "pdf.cell(40, 10, \"Predicted Class\", 1)\n",
        "pdf.cell(50, 10, \"Confidence Score\", 1)\n",
        "pdf.ln()\n",
        "\n",
        "pdf.set_font(\"Times\", size=12)\n",
        "for idx, row in df.iterrows():\n",
        "    pdf.cell(140, 10, row[\"Image Name\"], 1)\n",
        "    pdf.cell(40, 10, row[\"Folder\"], 1)\n",
        "    pdf.cell(40, 10, row[\"Predicted Class\"], 1)\n",
        "    pdf.cell(50, 10, str(row[\"Confidence Score\"]), 1)\n",
        "    pdf.ln()\n",
        "\n",
        "# üìä Insert Pie Charts\n",
        "pdf.ln(10)\n",
        "pdf.cell(0, 10, \"Class Distribution\", ln=True, align=\"L\")\n",
        "pdf.image(\"/content/class_distribution.png\", x=10, w=250)\n",
        "\n",
        "# üìâ Insert Average Confidence Score Chart\n",
        "pdf.ln(10)\n",
        "pdf.cell(0, 10, \"Average Confidence Score per Subfolder\", ln=True, align=\"L\")\n",
        "pdf.image(\"/content/avg_confidence.png\", x=10, w=250)\n",
        "\n",
        "# üíæ Save PDF to Drive\n",
        "pdf.output(output_pdf_path)\n",
        "print(f\"‚úÖ Report saved at: {output_pdf_path}\")"
      ],
      "metadata": {
        "id": "Rjevt6ogUUCX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}