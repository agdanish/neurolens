{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM3lLLpXQ1nvvZKs26cCSqC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<center>  \n","$$ \\huge \\textbf{FundusI3: InceptionV3 Model} $$  üè•üëÅÔ∏è  \n","</center>  \n","\n","**Purpose:**  \n","- üí° Classifies fundus images as 'Normal' or 'AbNormal' for Alzheimer's detection.  \n","\n","**Model Overview:**  \n","- üîë **Backbone:** InceptionV3 ‚Äî A deep CNN designed for **efficient feature extraction** with factorized convolutions.  \n","\n","**Techniques Used:**  \n","- üîÑ **Transfer Learning:** Pre-trained on ImageNet for improved generalization.  \n","- ‚öñÔ∏è **Binary Cross-Entropy Loss** for classification.  \n","- üöÄ **AdamW Optimizer** with weight decay for stability.  \n","- ‚öñÔ∏è **Class Weighting** to handle dataset imbalance.  \n","- üîé **Feature Extraction:** Uses **final convolutional block + ‚Äòmixed7‚Äô layer** for enriched representation.  \n","- ‚è±Ô∏è **Callbacks:** Early stopping, ReduceLROnPlateau & Model Checkpointing for optimized training.  "],"metadata":{"id":"qQJBqe78D0ZR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xKmmhE3mha8X"},"outputs":[],"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import InceptionV3\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","# Dataset Paths\n","train_dir = \"/content/drive/MyDrive/Fundus-ModelData/Train-Imgs\"\n","test_dir = \"/content/drive/MyDrive/Fundus-ModelData/Test-Imgs\"\n","\n","# Image Parameters\n","IMG_SIZE = 224\n","BATCH_SIZE = 32\n","\n","# Data Augmentation\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    horizontal_flip=True,\n","    brightness_range=[0.8, 1.2],\n","    validation_split=0.2  # 20% Validation Split\n",")\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,\n","    class_mode='binary',\n","    subset='training'\n",")\n","\n","val_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,\n","    class_mode='binary',\n","    subset='validation'\n",")\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,\n","    class_mode='binary',\n","    shuffle=False\n",")\n","\n","# Compute Class Weights\n","class_labels = train_generator.class_indices\n","num_samples = train_generator.samples\n","class_counts = [789, 405]  # AbNormal, Normal counts\n","\n","class_weights = compute_class_weight(\n","    class_weight=\"balanced\",\n","    classes=np.unique(list(class_labels.values())),\n","    y=np.concatenate([np.ones(class_counts[0]), np.zeros(class_counts[1])])\n",")\n","\n","class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n","print(\"Class Weights:\", class_weight_dict)\n","\n","# Load InceptionV3 Model\n","base_model = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n","\n","# Extract Features from 'mixed7' and Final Layer\n","x1 = base_model.get_layer(\"mixed7\").output\n","x1 = GlobalAveragePooling2D()(x1)\n","\n","x2 = base_model.output\n","x2 = GlobalAveragePooling2D()(x2)\n","\n","# Concatenate Features\n","x = tf.keras.layers.concatenate([x1, x2])\n","x = Dropout(0.4)(x)\n","x = Dense(256, activation=\"relu\")(x)\n","x = Dropout(0.3)(x)\n","output = Dense(1, activation=\"sigmoid\")(x)\n","\n","# Final Model\n","model = Model(inputs=base_model.input, outputs=output)\n","\n","# Freeze Backbone (First Training Phase)\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Compile Model\n","model.compile(\n","    optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-3),\n","    loss=\"binary_crossentropy\",\n","    metrics=[\"accuracy\"]\n",")\n","\n","# Callbacks\n","checkpoint = ModelCheckpoint(\"FundusI3_best_model.h5\", save_best_only=True, monitor=\"val_loss\", mode=\"min\")\n","early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n","reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3)\n","\n","callbacks = [checkpoint, early_stop, reduce_lr]\n","\n","# Train Model (Phase 1: Feature Extraction)\n","history = model.fit(\n","    train_generator,\n","    epochs=10,\n","    validation_data=val_generator,\n","    class_weight=class_weight_dict,\n","    callbacks=callbacks\n",")\n","\n","# Unfreeze Some Layers for Fine-Tuning\n","for layer in base_model.layers[-30:]:  # Unfreeze last 30 layers\n","    layer.trainable = True\n","\n","# Compile Again with Lower LR\n","model.compile(\n","    optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-4),\n","    loss=\"binary_crossentropy\",\n","    metrics=[\"accuracy\"]\n",")\n","\n","# Train Model (Phase 2: Fine-Tuning)\n","history_finetune = model.fit(\n","    train_generator,\n","    epochs=20,\n","    validation_data=val_generator,\n","    class_weight=class_weight_dict,\n","    callbacks=callbacks\n",")\n","\n","# Save Model\n","model.save(\"FundusI3_final_model.h5\")\n","print(\"FundusI3 Model Training Completed.\")"]},{"cell_type":"markdown","source":["**Prediction:**  \n","- üßë‚Äçüíª Predict whether new fundus images are 'Normal' or 'AbNormal'.  \n","\n","**Steps:**  \n","1. üìÇ Load the pre-trained **FundusI3** model.  \n","2. üîÑ Preprocess the images (resize to 224x224 & normalize pixel values).  \n","3. üìä Run the preprocessed images through the **InceptionV3** model for predictions.  \n","4. üßê Display the prediction result (Normal üü¢ or AbNormal üî¥) along with the confidence score.  "],"metadata":{"id":"Et0QYhvrElpL"}},{"cell_type":"code","source":["import tensorflow as tf\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from fpdf import FPDF\n","from google.colab import drive\n","\n","# üöÄ Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# üîç Define paths\n","model_path = \"/content/FundusI3_best_model.h5\"  # Update with your saved model path\n","test_folder = \"/content/drive/MyDrive/Fundus-ModelData/Test-Imgs\"  # Folder containing subfolders with images\n","output_pdf_path = \"/content/drive/MyDrive/Fundus-ModelData/FundusI3-Report\"\n","\n","# üß† Load Trained Model\n","model = tf.keras.models.load_model(model_path)\n","\n","# üñº Preprocess Image\n","def preprocess_image(image_path):\n","    img = load_img(image_path, target_size=(224, 224))  # Resize\n","    img_array = img_to_array(img) / 255.0  # Normalize\n","    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n","    return img_array\n","\n","# üìÇ Process Images & Predict\n","results = []\n","class_counts = {}  # For Pie Chart\n","confidence_scores = {}  # For Average Confidence Chart\n","threshold = 0.5  # Sigmoid activation threshold\n","\n","for subfolder in os.listdir(test_folder):\n","    subfolder_path = os.path.join(test_folder, subfolder)\n","\n","    if os.path.isdir(subfolder_path):  # Ensure it's a folder\n","        class_counts[subfolder] = {\"Normal\": 0, \"AbNormal\": 0}\n","        confidence_scores[subfolder] = []\n","\n","        for image_name in os.listdir(subfolder_path):\n","            image_path = os.path.join(subfolder_path, image_name)\n","\n","            # Predict class\n","            img_array = preprocess_image(image_path)\n","            prediction = model.predict(img_array)[0][0]\n","            predicted_class = \"AbNormal\" if prediction > threshold else \"Normal\"\n","            confidence_score = round(prediction, 4)\n","\n","            # Track counts & confidence\n","            class_counts[subfolder][predicted_class] += 1\n","            confidence_scores[subfolder].append(confidence_score)\n","\n","            # Store results\n","            results.append([image_name, subfolder, predicted_class, confidence_score])\n","\n","# üìù Convert results to DataFrame\n","df = pd.DataFrame(results, columns=[\"Image Name\", \"Folder\", \"Predicted Class\", \"Confidence Score\"])\n","\n","# üé® Generate Data Visualizations\n","fig, axes = plt.subplots(1, len(class_counts), figsize=(10, 5))\n","for i, (folder, counts) in enumerate(class_counts.items()):\n","    labels = counts.keys()\n","    sizes = counts.values()\n","    axes[i].pie(sizes, labels=labels, autopct=\"%1.1f%%\", startangle=90, colors=[\"lightblue\", \"salmon\"])\n","    axes[i].set_title(f\"Class Distribution in {folder}\")\n","plt.savefig(\"/content/class_distribution.png\")\n","\n","# üìä Average Confidence per Folder\n","avg_confidence = {folder: np.mean(scores) for folder, scores in confidence_scores.items()}\n","plt.figure(figsize=(6, 4))\n","plt.bar(avg_confidence.keys(), avg_confidence.values(), color=\"skyblue\")\n","plt.xlabel(\"Folders\")\n","plt.ylabel(\"Average Confidence Score\")\n","plt.title(\"Average Confidence Score per Subfolder\")\n","plt.savefig(\"/content/avg_confidence.png\")\n","\n","!pip install fpdf\n","\n","# üìÑ Generate PDF Report\n","class PDF(FPDF):\n","    def header(self):\n","        self.set_font(\"Times\", \"B\", 16)\n","        self.cell(275, 10, \"Fundus Image Classification Report\", ln=True, align=\"C\")\n","\n","    def footer(self):\n","        self.set_y(-15)\n","        self.set_font(\"Times\", \"I\", 10)\n","        self.cell(0, 10, f\"Page {self.page_no()}\", align=\"C\")\n","\n","# üìë Create PDF\n","pdf = PDF(orientation=\"L\")  # Landscape Mode\n","pdf.set_auto_page_break(auto=True, margin=15)\n","pdf.add_page()\n","pdf.set_font(\"Times\", size=12)\n","\n","# üè∑ Report Header\n","pdf.set_font(\"Times\", \"B\", 14)\n","pdf.cell(0, 10, \"Model Details\", ln=True)\n","pdf.set_font(\"Times\", size=12)\n","pdf.cell(0, 10, f\"Model Name: FundusR50\", ln=True)\n","#pdf.cell(0, 10, f\"Model Path: {model_path}\", ln=True)\n","pdf.cell(0, 10, \"Author: Danish A. G.\", ln=True)\n","pdf.ln(10)\n","\n","# üìã Results Table\n","pdf.set_font(\"Times\", \"B\", 12)\n","\n","# Adjusted Column Widths\n","pdf.cell(140, 10, \"Image Name\", 1)  # Increased width\n","pdf.cell(40, 10, \"Folder\", 1)\n","pdf.cell(40, 10, \"Predicted Class\", 1)\n","pdf.cell(50, 10, \"Confidence Score\", 1)\n","pdf.ln()\n","\n","pdf.set_font(\"Times\", size=12)\n","for idx, row in df.iterrows():\n","    pdf.cell(140, 10, row[\"Image Name\"], 1)  # Adjusted width\n","    pdf.cell(40, 10, row[\"Folder\"], 1)\n","    pdf.cell(40, 10, row[\"Predicted Class\"], 1)\n","    pdf.cell(50, 10, str(row[\"Confidence Score\"]), 1)\n","    pdf.ln()\n","\n","# üìä Insert Pie Charts\n","pdf.ln(10)\n","pdf.cell(0, 10, \"Class Distribution\", ln=True, align=\"L\")\n","pdf.image(\"/content/class_distribution.png\", x=10, w=250)\n","\n","# üìâ Insert Average Confidence Score Chart\n","pdf.ln(10)\n","pdf.cell(0, 10, \"Average Confidence Score per Subfolder\", ln=True, align=\"L\")\n","pdf.image(\"/content/avg_confidence.png\", x=10, w=250)\n","\n","# üíæ Save PDF to Drive\n","pdf.output(output_pdf_path)\n","print(f\"‚úÖ Report saved at: {output_pdf_path}\")"],"metadata":{"id":"9cSEz6uu3_Yq"},"execution_count":null,"outputs":[]}]}